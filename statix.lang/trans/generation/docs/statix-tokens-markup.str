module generation/docs/statix-tokens-markup

imports

  libstratego-lib
  
rules // Tokens

  // gen-tokens-markup(|ins:stream, outs:stream):
  // - reads all remaining chars from ins
  // - forms the corresponding string for displaying those chars in HTML
  // - inserts markup for highllghting all tokens in the string
  // - writes the marked-up string to outs
  
  gen-tokens-markup(|ins, outs) = 
    <fputs> (<gen-fgetcs; map(char-to-html-string); concat-strings; markup-tokens> ins, outs)

  // gen-tokens-markup(|ins:stream, outs:stream, n:int):
  // - reads exactly n chars from ins
  // - otherwise as gen-tokens-markup(|ins, outs)

  gen-tokens-markup(|ins, outs, n) =
    <fputs> (<gen-fgetcs(|n); map(char-to-html-string); concat-strings; markup-tokens> ins, outs)
  
  gen-copy(|ins, outs, n) =
    repeat(<fputs> (<fgetc; char-to-html-string> ins, outs) | n)
  
  gen-fgetcs:
    ins -> [c | cs]
    where
      c := <fgetc> ins
    ; cs :=  <gen-fgetcs> ins
  
  gen-fgetcs:
    ins -> []
  
  gen-fgetcs(|n):
    ins -> [c | cs]
    where
      <gti> (n, 0)
    ; c := <fgetc> ins
    ; cs :=  <gen-fgetcs(| <int-dec> n)> ins
  
  gen-fgetcs(|0):
    ins -> []

  char-to-html-string: '&' -> "&amp;"
  char-to-html-string: '<' -> "&lt;"
  char-to-html-string: '>' -> "&gt;"
  char-to-html-string: '\t' -> "        " // 8 spaces (Python-Markdown maps tabs in HTML to 4 spaces)
  char-to-html-string: c -> <implode-string> [c]

  // markup-tokens: html:string -> html':string
  // - adds markup for highlighting all tokens in the html string
  
  markup-tokens: "" -> ""
  
  markup-tokens:
    html -> <conc-strings> (token, tokens)
    where
      (token, html') := <markup-token> html
    ; tokens := <markup-tokens> html'

  // markup-token: html:string -> (token:string, html':string)
  // - assumes html is non-empty
  // - token is the html markup of the first token in html
  // - html' is the un-markedup rest of html
  // - the order of scanning for specific kinds of token follows JSGLR:
  //   https://github.com/metaborg/jsglr/blob/master/org.spoofax.jsglr/src/org/spoofax/jsglr/client/imploder/TokenKindManager.java

/*
  statix.lang/editor/Colorer.esv:

  RuleLabel._ : 0 0 139
  
  //RelationId : 38 139 210 bold // blue   
  
  //ConstraintId : 8 0 255   // dark blue  
  ConstraintId : 0 0 109   // dark blue   
  
  NamespaceId : 108 113 196 // violet

  VARID : 101 123 131 italic // base0
  
  UCID : 7 54 66 bold // base02
  LCID : black
  
  ID :  88 110 117 // base02
  
  Str : 0 128 0       // darkgreen
  
  FileID : yellow
  ModuleID : blue
  
  STRID : 0 0 255 bold // blue   
  
  OpId : 7 54 66 bold // base02
  
  MessageChars : 181 137   0 // yellow
*/

/*
  statix.lang/syntax/-

  RuleLabel ?

  ConstraintId = LCID
  ConstraintId = Keyword {reject}

  NamespaceId = UCID

  VARID  = [a-zA-Z] [a-zA-Z0-9\_]* [\']*
  VARID -/- [a-zA-Z0-9\_\']
  VARID = "new" {reject}

  UCID   = [A-Z]    [a-zA-Z0-9\_]*
  UCID  -/- [a-zA-Z0-9\_\']

  LCID   = [a-z]    [a-zA-Z0-9\_]*
  LCID  -/- [a-zA-Z0-9\_\']

  ID     = [a-zA-Z] [a-zA-Z0-9\_]*
  ID    -/- [a-zA-Z0-9\_\']

  Str-CF.Str        = "\"" StrChars-LEX "\""
  StrChars   = StrChar*
  StrChar    = ~[\"\\\t\r\n]
  StrChar    =  "\\\"" | "\\\\" | "\\t" | "\\r" | "\\n"
  StrChars -/- ~[\"]

  FileId   = [a-zA-Z0-9\_\-\.\~\']+
  FileId   -/- [a-zA-Z0-9\_\-\.\~\']

  ModuleId = FileId ("/" FileId)*
  ModuleId -/- [\/]

  STRID = [A-Z] [a-zA-Z0-9\_\-\']*
  STRID -/- [a-zA-Z0-9\_\-\']

  OpId = STRID
  OpId = Keyword {reject}

  MessageChars = MessageChar+
  MessageChar  = ~[\[\]\\\t\r\n]
  MessageChar  = "\\[" | "\\]" | "\\n" | "\\r" | "\\t" | "\\\\"
  MessageChars -/- ~[\[\]]

  Keyword = "module" | "imports" | "signature" | "rules"
  Keyword = "constraints" | "coinductive"
  Keyword = "true" | "false" | "new" | "try"
  Keyword = "astId"
  Keyword = "relations" | "relation" | "in"
  Keyword = "namespaces" | "name-resolution" | "labels" | "namespace"
  Keyword = "query" | "in" | "filter" | "min" | "project" | "and"
  Keyword = "sorts" | "constructors"

  Keyword = "constraint" | "maps"
  Keyword = "resolve" | "filter" | "with" | "and"
  Keyword = "filter" | "min" | "in" | "of" | "resolveMatch" | "resolveLt" | "occurrenceMatch"
*/

  
  
  markup-token =
    
    scan-token(scan-whitespace, id) 
    <+
    scan-token(scan-comment,    markup-token-kind(|"layout"))
    <+
    scan-token(scan-keywords,   markup-token-kind(|"keyword"))
    <+
    scan-token(scan-string-1,   id)
    <+
    scan-token(scan-string-2,   id)
//    <+
//    scan-token(scan-number,     markup-token-kind(|"number"))
    <+
    scan-token(scan-escape,     markup-token-kind(|"string"))
    <+
    scan-token(scan-unknown,    id)
//    <+
//    scan-token(scan-identifier, markup-token-kind(|"identifier"))
//    <+
//    scan-token(scan-operator,   markup-token-kind(|"operator"))
//    <+
//    scan-token(scan-var,        markup-token-kind(|"var"))


  // scan-token(scanner, kinder): html:string -> (token:string, html':string)
  // - assumes scanner: (char*, char*) -> (char*, char*)
  // - assumes kinder: html:string -> token:string
  // - when scanner matches a prefix of html (leaving html'), kinder returns token
  
  scan-token(scanner, kinder):
    html -> (token, html')
    where (scanned-chars, unscanned-chars) := <scanner> ([], <explode-string> html)
    ; token := <reverse; implode-string; kinder> scanned-chars
    ; html' := <implode-string> unscanned-chars
  
  // scan(p): cs1:List(Char) * cs2:List(Char) -> List(Char) * List(Char)
  // - assumes p: c:Char ->? c:Char
  // - when p holds for the head of cs2, moves that char to cs1
  
  scan(p):
    (scanned-chars, [char|unscanned-chars]) -> ([char|scanned-chars], unscanned-chars)
    where <p> char

  // scan(|s): List(Char) * List(Char) -> List(Char) * List(Char)
  // - assumes s:String
  // - scans all the chars of s
  
  scan(|s) =
      <explode-string> s

  markup-token-kind(|kind): token -> $[<span class="[kind]">[token]</span>]
  
  scan-whitespace = 
    repeat1( scan(?' ' + ?'\n' + ?'\r') ) // '\t' already mapped to spaces

  scan-comment =
    ( scan(?'%') ; scan(?'%') ; repeat( scan(not(?'\n' + ?'\r')) ) )
    +
    ( scan(?'%') ; repeat1( scan(not(?'%' + ?'\n' + ?'\r'))) ; scan(?'%') )
    +
    ( scan(?'/') ; scan(?'*') ; repeat( scan-comment-char ) ; scan(?'*') ; scan(?'/') )
    +
    ( scan(?'/') ; scan(?'/') ; repeat( scan(not(?'\n' + ?'\r')) ) )
    
  scan-comment-char =
    scan(not(?'*'))
    +
    ( scan(?'*') ; try( scan( not(?'/') ) ) )
  
  scan-keywords =
    scan-keyword ; repeat( repeat1( scan(?' ') ) ; scan-keyword )
  
  scan-keyword =
    scan(is-alpha) ; repeat( scan(is-alpha + ?'-') )
    +
    scan(?'-') ; scan(?'C') ; scan(?'F')
    +
    scan(?'-') ; scan(?'L') ; scan(?'E') ; scan(?'X')
    +
    scan(?'-') ; scan(?'V') ; scan(?'A') ; scan(?'R')

  scan-unknown =
    scan(?'&') ; repeat1( scan(is-lower) ) ; scan(?';')
    <+
    scan(id)

  scan-escape =
    scan(?'\') ; scan( not(?'&') )
    <+
    scan(?'\') ; scan(?'&') ; scan(?'a') ; scan(?'m') ; scan(?'p') ; scan(?';')
    <+
    scan(?'\') ; scan(?'&') ; scan(?'g') ; scan(?'t') ; scan(?';')
    <+
    scan(?'\') ; scan(?'&') ; scan(?'l') ; scan(?'t') ; scan(?';')

  scan-string-1 =
    scan(?'\'') ;
    repeat( scan-string-char-1 ) ;
    scan(?'\'')
  
  scan-string-char-1 =
    scan(not(?'\'' + ?'\'))
    +
    ( scan(?'\') ; scan(?'\' + ?'\'' + ?'n' + ?'t') )
    +
    ( scan(?'\') ; repeat( scan(is-num) | 3 ) )
  
  scan-string-2 =
    scan(?'"') ;
    repeat( scan-string-char-2 ) ;
    scan(?'"')
  
  scan-string-char-2 =
    scan(not(?'"' + ?'\'))
    +
    ( scan(?'\') ; scan(?'\' + ?'"' + ?'n' + ?'t') )
    +
    ( scan(?'\') ; repeat( scan(is-num) | 3 ) )

  scan-integer =
    try( scan(?'+' + ?'-') ) ; repeat1( scan(?is-num) )
   
  scan-number =
    scan-integer ; try( scan(?'.') ; repeat1( scan(?is-num) ) ; scan(?'e') ; scan-integer )

module generation/docs/statix-tokens-markup

imports

  libstratego-lib
  
rules // Tokens

  test-tokens-markup:
    (_, _, ast, path, project-path) -> ()
    where
      target := <guarantee-extension(|"txt")> path
    ; say(!target)
    ; ins := <fopen> (path, "r")
    ; outs := <fopen> (target, "w")
    ; gen-tokens-markup(|ins, outs)

  // gen-tokens-markup(|ins:stream, outs:stream):
  // - reads all remaining chars from ins
  // - forms the corresponding string for displaying those chars in HTML
  // - inserts markup for highllghting all tokens in the string
  // - writes the marked-up string to outs
  
  gen-tokens-markup(|ins, outs) = 
    <fputs> (<gen-fgetcs; map(char-to-html-string); concat-strings; markup-tokens> ins, outs)

  // gen-tokens-markup(|ins:stream, outs:stream, n:int):
  // - reads exactly n chars from ins
  // - otherwise as gen-tokens-markup(|ins, outs)

  gen-tokens-markup(|ins, outs, n) =
    <fputs> (<gen-fgetcs(|n); map(char-to-html-string); concat-strings; markup-tokens> ins, outs)
  
  gen-copy(|ins, outs, n) =
    repeat(<fputs> (<fgetc; char-to-html-string> ins, outs) | n)
  
  gen-fgetcs:
    ins -> [c | cs]
    where
      c := <fgetc> ins
    ; cs :=  <gen-fgetcs> ins
  
  gen-fgetcs:
    ins -> []
  
  gen-fgetcs(|n):
    ins -> [c | cs]
    where
      <gti> (n, 0)
    ; c := <fgetc> ins
    ; cs :=  <gen-fgetcs(| <int-dec> n)> ins
  
  gen-fgetcs(|0):
    ins -> []

  char-to-html-string: '&' -> "&amp;"
  char-to-html-string: '<' -> "&lt;"
  char-to-html-string: '>' -> "&gt;"
  char-to-html-string: '\t' -> "        " // 8 spaces (Python-Markdown maps tabs in HTML to 4 spaces)
  char-to-html-string: c -> <implode-string> [c]

rules // Markup tokens

  // markup-tokens: html:string -> html':string
  // - adds markup for highlighting all tokens in the html string
  
  markup-tokens: "" -> ""
  
  markup-tokens:
    html -> <conc-strings> (token, tokens)
    where
      (token, html') := <markup-token> html
    ; tokens := <markup-tokens> html'

rules // Scan and markup a token

  // scan-token(scanner, kinder): html:string -> (token:string, html':string)
  // - assumes scanner: (char*, char*) -> (char*, char*)
  // - assumes kinder: html:string -> token:string
  // - when scanner matches a prefix of html (leaving html'), kinder returns token
  
  scan-token(scanner, kinder):
    html -> (token, html')
    where (scanned-chars, unscanned-chars) := <scanner> ([], <explode-string> html)
    ; token := <reverse; implode-string; kinder> scanned-chars
    ; html' := <implode-string> unscanned-chars
  
  // scan(p): cs1:List(Char) * cs2:List(Char) -> List(Char) * List(Char)
  // - assumes p: c:Char ->? c:Char
  // - when p holds for the head of cs2, moves that char to cs1
  
  scan(p):
    (scanned-chars, [char|unscanned-chars]) -> ([char|scanned-chars], unscanned-chars)
    where <p> char

  // scan(|s): List(Char) * List(Char) -> List(Char) * List(Char)
  // - assumes s:List(Char) or s:String
  // - scans all the chars of s
  
  scan(|[]) = id
  
  scan(|[char|chars]) = scan(equal(|char)) ; scan(|chars)
  
  scan(|s) = scan(|<explode-string> s)

rules // Kinder strategies:

  markup-token-kind(|kind): token -> $[<span class="[kind]">[token]</span>]

  markup-token-sort(|sort): token -> $[<span class="token sort_[sort]">[token]</span>]

rules // Token markup

  // markup-token: html:string -> (token:string, html':string)
  // - assumes html is non-empty
  // - token is the html markup of the first token in html
  // - html' is the un-markedup rest of html
  // - the order of scanning for specific kinds of token follows JSGLR:
  //   https://github.com/metaborg/jsglr/blob/master/org.spoofax.jsglr/src/org/spoofax/jsglr/client/imploder/TokenKindManager.java
  
  markup-token = scan-token(scan-whitespace, id) 
  markup-token = scan-token(scan-comment,    markup-token-kind(|"layout"))
  markup-token = scan-token(scan-keyword,    markup-token-kind(|"keyword"))
//  markup-token = scan-token(scan-string-1,   id)
//  markup-token = scan-token(scan-string-2,   id)
//markup-token = scan-token(scan-number,     markup-token-kind(|"number"))
  markup-token = scan-token(scan-escape,     markup-token-kind(|"string"))
//markup-token = scan-token(scan-identifier, markup-token-kind(|"identifier"))
markup-token = scan-token(scan-operator,   markup-token-kind(|"operator"))
//markup-token = scan-token(scan-var,        markup-token-kind(|"var"))

/*
  statix.lang/editor/Colorer.esv:

  RuleLabel._ : 0 0 139
  
  //RelationId : 38 139 210 bold // blue   
  
  //ConstraintId : 8 0 255   // dark blue  
  ConstraintId : 0 0 109   // dark blue   
  
  NamespaceId : 108 113 196 // violet

  VARID : 101 123 131 italic // base0
  
  UCID : 7 54 66 bold // base02
  LCID : black
  
  ID :  88 110 117 // base02
  
  Str : 0 128 0       // darkgreen
  
  FileID : yellow
  ModuleID : blue
  
  STRID : 0 0 255 bold // blue   
  
  OpId : 7 54 66 bold // base02
  
  MessageChars : 181 137   0 // yellow
*/

//  markup-token = scan-token(scan-rule-label,    markup-token-sort(|"RuleLabel"))
  markup-token = scan-token(scan-constraint-id, markup-token-sort(|"ConstraintId"))
//  markup-token = scan-token(scan-namespace-id,  markup-token-sort(|"NamespaceId"))
//  markup-token = scan-token(scan-var-id,        markup-token-sort(|"VARID"))
//  markup-token = scan-token(scan-uc-id,         markup-token-sort(|"UCID"))
//  markup-token = scan-token(scan-lc-id,         markup-token-sort(|"LCID"))
//  markup-token = scan-token(scan-str,           markup-token-sort(|"Str"))
//  markup-token = scan-token(scan-file-id,       markup-token-sort(|"FileID"))
//  markup-token = scan-token(scan-module-id,     markup-token-sort(|"ModuleID"))
//  markup-token = scan-token(scan-str-id,        markup-token-sort(|"STRID"))
  markup-token = scan-token(scan-op-id,         markup-token-sort(|"OpId"))
//  markup-token = scan-token(scan-message-chars, markup-token-sort(|"MessageChars"))

  markup-token = scan-token(scan-id,            markup-token-sort(|"ID"))

  markup-token = scan-token(scan-unknown,    id)

rules // Scanners:
  
  // Fixed token types:

  scan-whitespace = repeat1( scan(?' ' + ?'\n' + ?'\r') ) // '\t' already mapped to spaces

  scan-comment = ( scan(?'%') ; scan(?'%') ; repeat( scan(not(?'\n' + ?'\r')) ) )
  scan-comment = ( scan(?'%') ; repeat1( scan(not(?'%' + ?'\n' + ?'\r'))) ; scan(?'%') )
  scan-comment = ( scan(?'/') ; scan(?'*') ; repeat( scan-comment-char ) ; scan(?'*') ; scan(?'/') )
  scan-comment = ( scan(?'/') ; scan(?'/') ; repeat( scan(not(?'\n' + ?'\r')) ) )
    
  scan-comment-char = scan(not(?'*'))
  scan-comment-char = ( scan(?'*') ; try( scan( not(?'/') ) ) )
  
//  scan-keywords = scan-keyword ; repeat( repeat1( scan(?' ') ) ; scan-keyword )
  
//  scan-keyword = scan(is-alpha) ; repeat( scan(is-alpha + ?'-') )
//  scan-keyword = scan(?'-') ; scan(?'C') ; scan(?'F')
//  scan-keyword = scan(?'-') ; scan(?'L') ; scan(?'E') ; scan(?'X')
//  scan-keyword = scan(?'-') ; scan(?'V') ; scan(?'A') ; scan(?'R')

  scan-unknown = scan(?'&') ; repeat1( scan(is-lower) ) ; scan(?';')
  scan-unknown = scan(id)

  scan-escape = scan(?'\') ; scan( not(?'&') )
  scan-escape = scan(?'\') ; scan-html
  
  scan-html = scan(|"&amp;")
  scan-html = scan(|"&lt;")
  scan-html = scan(|"&gt;")

  scan-operator = repeat1 ( scan-html <+ scan( not(is-alphanum + ?' ' + ?'\n' + ?'\r') ) )

  scan-string-1 = scan(?'\'') ; repeat( scan-string-char-1 ) ; scan(?'\'')
 
  scan-string-char-1 = scan(not(?'\'' + ?'\'))
  scan-string-char-1 = scan(?'\') ; scan(?'\' + ?'\'' + ?'n' + ?'t')
  scan-string-char-1 = scan(?'\') ; repeat( scan(is-num) | 3 )
  
  scan-string-2 = scan(?'"') ; repeat( scan-string-char-2 ) ; scan(?'"')
  
  scan-string-char-2 = scan(not(?'"' + ?'\'))
  scan-string-char-2 = scan(?'\') ; scan(?'\' + ?'"' + ?'n' + ?'t')
  scan-string-char-2 = scan(?'\') ; repeat( scan(is-num) | 3 )

  scan-integer = try( scan(?'+' + ?'-') ) ; repeat1( scan(?is-num) )
   
  scan-number = scan-integer ; try( scan(?'.') ; repeat1( scan(?is-num) ) ; scan(?'e') ; scan-integer )

/*
  statix.lang/syntax/-

  RuleLabel ?

  ConstraintId = LCID
  ConstraintId = Keyword {reject}

  NamespaceId = UCID

  VARID  = [a-zA-Z] [a-zA-Z0-9\_]* [\']*
  VARID -/- [a-zA-Z0-9\_\']
  VARID = "new" {reject}

  UCID   = [A-Z]    [a-zA-Z0-9\_]*
  UCID  -/- [a-zA-Z0-9\_\']

  LCID   = [a-z]    [a-zA-Z0-9\_]*
  LCID  -/- [a-zA-Z0-9\_\']

  ID     = [a-zA-Z] [a-zA-Z0-9\_]*
  ID    -/- [a-zA-Z0-9\_\']

  Str-CF.Str        = "\"" StrChars-LEX "\""
  StrChars   = StrChar*
  StrChar    = ~[\"\\\t\r\n]
  StrChar    =  "\\\"" | "\\\\" | "\\t" | "\\r" | "\\n"
  StrChars -/- ~[\"]

  FileId   = [a-zA-Z0-9\_\-\.\~\']+
  FileId   -/- [a-zA-Z0-9\_\-\.\~\']

  ModuleId = FileId ("/" FileId)*
  ModuleId -/- [\/]

  STRID = [A-Z] [a-zA-Z0-9\_\-\']*
  STRID -/- [a-zA-Z0-9\_\-\']

  OpId = STRID
  OpId = Keyword {reject}

  MessageChars = MessageChar+
  MessageChar  = ~[\[\]\\\t\r\n]
  MessageChar  = "\\[" | "\\]" | "\\n" | "\\r" | "\\t" | "\\\\"
  MessageChars -/- ~[\[\]]

  Keyword = "module" | "imports" | "signature" | "rules"
  Keyword = "constraints" | "coinductive"
  Keyword = "true" | "false" | "new" | "try"
  Keyword = "astId"
  Keyword = "relations" | "relation" | "in"
  Keyword = "namespaces" | "name-resolution" | "labels" | "namespace"
  Keyword = "query" | "in" | "filter" | "min" | "project" | "and"
  Keyword = "sorts" | "constructors"

  Keyword = "constraint" | "maps"
  Keyword = "resolve" | "filter" | "with" | "and"
  Keyword = "filter" | "min" | "in" | "of" | "resolveMatch" | "resolveLt" | "occurrenceMatch"
*/

  // scan-keyword is tried before other tokens, so reject-rules are implicit
  // - for longest-match, plurals need to be tried before singular forms
  
  scan-keyword = scan(|"and")
  scan-keyword = scan(|"astId")
  scan-keyword = scan(|"coinductive")
  scan-keyword = scan(|"constraints")
  scan-keyword = scan(|"constraint")
  scan-keyword = scan(|"constructors")
  scan-keyword = scan(|"false")
  scan-keyword = scan(|"filter")
  scan-keyword = scan(|"imports")
  scan-keyword = scan(|"in")
  scan-keyword = scan(|"labels")
  scan-keyword = scan(|"maps")
  scan-keyword = scan(|"min")
  scan-keyword = scan(|"module")
  scan-keyword = scan(|"name-resolution")
  scan-keyword = scan(|"namespaces")
  scan-keyword = scan(|"namespace")
  scan-keyword = scan(|"new")
  scan-keyword = scan(|"occurrenceMatch")
  scan-keyword = scan(|"of")
  scan-keyword = scan(|"project")
  scan-keyword = scan(|"query")
  scan-keyword = scan(|"relations")
  scan-keyword = scan(|"relation")
  scan-keyword = scan(|"resolveLt")
  scan-keyword = scan(|"resolveMatch")
  scan-keyword = scan(|"resolve")
  scan-keyword = scan(|"rules")
  scan-keyword = scan(|"signature")
  scan-keyword = scan(|"sorts")
  scan-keyword = scan(|"true")
  scan-keyword = scan(|"try")
  scan-keyword = scan(|"with")
  
  scan-rule-label = fail // no syntax found
  
  scan-constraint-id = scan-lc-id 
  
  scan-namespace-id = scan-lc-id
  
  scan-var-id    = scan(is-alpha) ; repeat(scan(is-alphanum + ?'_')) ; repeat(scan(?'\'')) ; not(scan(is-alphanum + ?'_'))
  
  scan-uc-id     = scan(is-upper) ; repeat(scan(is-alphanum + ?'_')) ; not(scan(?'\''))

  scan-lc-id     = scan(is-lower) ; repeat(scan(is-alphanum + ?'_')) ; not(scan(?'\''))

  scan-id        = scan(is-alpha) ; repeat(scan(is-alphanum + ?'_')) ; not(scan(?'\''))

  scan-str       = scan(?'"') ; repeat( scan-str-char ) ; scan(?'"')
  
  scan-str-char  = scan(not(?'"' + ?'\' + ?'\t' + ?'\r' + ?'\n'))
  scan-str-char  = scan(|"\\\"")
  scan-str-char  = scan(|"\\\\")
  scan-str-char  = scan(|"\\t")
  scan-str-char  = scan(|"\\r")
  scan-str-char  = scan(|"\\n")
  
  scan-file-id   = repeat1(scan(is-alphanum + ?'_' + ?'-' + ?'.' + ?'~' + ?'\''))
  
  scan-module-id = scan-file-id ; repeat( scan(?'/') ; scan-file-id )
  
  scan-str-id    = scan(is-upper) ; repeat(scan(is-alphanum + ?'_' + ?'-'))
  
  scan-op-id     = scan-str-id
  
  scan-message-chars = repeat1( scan-message-char ) ; where(scan(?'[' + ?']'))
  
  scan-message-char  = scan(not(?'[' + ?']' + ?'\' + ?'\t' + ?'\r' + ?'\n'))
  scan-message-char  = scan(|"\\[")
  scan-message-char  = scan(|"\\]")
  scan-message-char  = scan(|"\\\\")
  scan-message-char  = scan(|"\\t")
  scan-message-char  = scan(|"\\r")
  scan-message-char  = scan(|"\\n")
 